{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import skimage\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "from pprint import pprint\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SatelliteImageDataset(Dataset):\n",
    "    \"\"\"Load a satellite dataset\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, transform=None, device=torch.device(\"cpu\")):\n",
    "        \"\"\"\n",
    "        Create a satellite image dataset\n",
    "        :param root_dir: String, The path where are stored the images\n",
    "        :param transform: torchvion transform function, Optional transform to be applied\n",
    "                on an image.\n",
    "        :device: Pytorch device: cpu or gpu to move the data into the good device\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.L_image_name = os.listdir(root_dir)\n",
    "        self.transform = transform\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.L_image_name)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        image = pil_loader(os.path.join(self.root_dir,\n",
    "                             self.L_image_name[idx]))\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image.to(self.device)\n",
    "\n",
    "def pil_loader(path):\n",
    "    \"\"\"\n",
    "    Load an image into PIL format and convert it into RGB    \n",
    "    :param path: String, Complete path of the image file\n",
    "    :return: PIL image\n",
    "    \"\"\"\n",
    "    image = Image.open(path)\n",
    "    return image.convert(\"RGB\")\n",
    "    \n",
    "def show_tensor_image(tensor):\n",
    "    \"\"\"\n",
    "    Take a tensor and show the corresponding image\n",
    "    :param tensor: Pytorch Tensor, [channels, height, width]\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    tensor = tensor.transpose(0, 1)\n",
    "    tensor = tensor.transpose(1, 2)\n",
    "    io.imshow(tensor.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def create_list_box(img, coord, grid_box = [100, 150, 200]):\n",
    "    \"\"\"\n",
    "    From tile and box coordinates of boat, create images with\n",
    "    different size of bounding boxes (defined by grid_box)\n",
    "    :param img: 3D Numpy Array (768,768,3), correspond to the tile\n",
    "    :param coord: List, represents xmin, xmax, ymin, ymax of the box\n",
    "    :param grid_box: List, references the number of pixel to add to the\n",
    "        original bounding box\n",
    "    :return: List, of 3D Numpy Array (different size)\n",
    "    \"\"\"\n",
    "    xmin, xmax, ymin, ymax = coord\n",
    "    list_box = []\n",
    "    for npi in grid_box:\n",
    "\n",
    "        ymax_npi = ymax+npi\n",
    "        ymin_npi = ymin-npi\n",
    "        xmax_npi = xmax+npi\n",
    "        xmin_npi = xmin-npi\n",
    "\n",
    "        if ymax_npi > 768:\n",
    "            ymax_npi = 768\n",
    "        if ymin_npi < 0:\n",
    "            ymin_npi = 0\n",
    "        if xmax_npi > 768:\n",
    "            xmax_npi = 768\n",
    "        if xmin_npi < 0:\n",
    "            xmin_npi = 0\n",
    "\n",
    "        list_box.append(img[ymin_npi:ymax_npi, xmin_npi:xmax_npi])\n",
    "    return list_box\n",
    "\n",
    "\n",
    "def save_list_box(list_box, grid_box, data_clean_dir, record_id):\n",
    "    \"\"\"\n",
    "    Take the list_box from create_list_box and save each image (box) to\n",
    "    the directory path_dir with name record_id + the number of pixel added\n",
    "    :param list_box: List, of 3D Numpy Array (different size)\n",
    "    :param grid_box: grid_box: List, references the number of pixel to add to the\n",
    "        original bounding box\n",
    "    :param data_clean_dir: String, path of the directory\n",
    "    :param record_id: String, id of the boat's box\n",
    "    :return: l_dir_image_clean, List, record_id and path of clean images saved\n",
    "    \"\"\"\n",
    "    if not os.path.exists(data_clean_dir):\n",
    "        os.makedirs(data_clean_dir)\n",
    "    l_dir_image_clean = []\n",
    "    for box, npi in zip(list_box, grid_box):\n",
    "        io.imsave(os.path.join(data_clean_dir, record_id+'_'+str(npi)+\".jpg\"), box, check_contrast=False)\n",
    "        l_dir_image_clean.append([record_id, os.path.join(data_clean_dir, record_id+'_'+str(npi)+\".jpg\")])\n",
    "    return l_dir_image_clean\n",
    "\n",
    "def create_list_label_sample(data_dir, dataset_name):\n",
    "    \"\"\"\n",
    "    Generate two lists of complete path for both tiles and labels\n",
    "    The two folders in dataset_name are named \"samples\" and \"labels\"\n",
    "    Return intersection of the two lists by file name\n",
    "    :param data_dir: String, path of the data\n",
    "    :param dataset_name: name of the dataset in data_dir\n",
    "    :return: list_sample_path: List, list of complete path of tiles\n",
    "             list_label_path: List, list of complete path of labels\n",
    "    \"\"\"\n",
    "    def list_sorted(name):\n",
    "        list_ = []\n",
    "        for dir_, _, filenames in os.walk(os.path.join(data_dir,dataset_name, name)):\n",
    "            for f in filenames:\n",
    "                if f[0] != \".\":\n",
    "                    list_.append(os.path.abspath(os.path.join(dir_, f)))\n",
    "        list_.sort(key=lambda f: f.split('/')[-1])\n",
    "        return list_\n",
    "    list_sample_path, list_label_path = list_sorted(\"samples\"), list_sorted(\"labels\")\n",
    "    set_sample_id = set(list(map(lambda x: x.split('/')[-1].replace(\".jpg\",\"\"), list_sample_path)))\n",
    "    set_label_id = set(list(map(lambda x: x.split('/')[-1].replace(\".json\",\"\"), list_label_path)))\n",
    "    id_diff = set_sample_id.difference(set_label_id)\n",
    "    id_diff.update(set_label_id.difference(set_sample_id))\n",
    "    list_sample_path = list(filter(lambda x: x.split('/')[-1].replace(\".jpg\",\"\") not in id_diff, list_sample_path))\n",
    "    list_label_path = list(filter(lambda x: x.split('/')[-1].replace(\".json\",\"\") not in id_diff, list_label_path))\n",
    "    return list_sample_path, list_label_path\n",
    "\n",
    "\n",
    "def polygone_to_min_max_coordinates(polygon):\n",
    "    \"\"\"\n",
    "    Get the min and max pixel of the polygon (casted to int)\n",
    "    :param polygon: List, coordinates of the bounding box\n",
    "    :return: Tuple, of int xmin, xmax, ymin, ymax\n",
    "    \"\"\"\n",
    "    # Remove the last point that correspond to the first one\n",
    "    polygon = np.array(polygon[:-1])\n",
    "    # Get min and max coordinates transformed to int\n",
    "    xmin = int(np.min(polygon[:, 0]))\n",
    "    xmax = int(np.max(polygon[:, 0])) + 1\n",
    "    ymin = int(np.min(polygon[:, 1]))\n",
    "    ymax = int(np.max(polygon[:, 1])) + 1\n",
    "    return xmin, xmax, ymin, ymax\n",
    "\n",
    "\n",
    "def boat_info_from_json(label_path, image_path):\n",
    "    \"\"\"\n",
    "    From a label_path and image_path get all boats info present in the image.\n",
    "    Return the list of info for each boat.\n",
    "    :param label_path: String, path to the label\n",
    "    :param image_path: String, path to the image\n",
    "    :return: l_res: List, list of basic info get from the json for each boat\n",
    "    \"\"\"\n",
    "    # read the json file containing the boat info\n",
    "    with open(label_path, 'rb') as f:\n",
    "        boat_info = json.load(f)\n",
    "    # l_res contains the final info to keep\n",
    "    l_res = []\n",
    "    for feature in boat_info[\"features\"]:\n",
    "        properties = feature[\"properties\"]\n",
    "        infos = []\n",
    "        # Finding the speed tag if not exists continue\n",
    "        if \"tags\" not in properties:\n",
    "            continue\n",
    "        speed = None\n",
    "        for speed_tag in [\"idle\", \"fast\", \"slow\"]:\n",
    "            if speed_tag in properties[\"tags\"]:\n",
    "                speed = speed_tag\n",
    "        # If there is not a record_id or not speed tag then continue\n",
    "        if \"record_id\" not in properties or speed is None:\n",
    "            continue\n",
    "        xmin, xmax, ymin, ymax = polygone_to_min_max_coordinates(feature[\"geometry\"][\"coordinates\"][0])\n",
    "        infos.append(properties[\"record_id\"])\n",
    "        # Appending all infos\n",
    "        infos.append(xmin)\n",
    "        infos.append(xmax)\n",
    "        infos.append(ymin)\n",
    "        infos.append(ymax)\n",
    "        infos.append(properties[\"angle\"])\n",
    "        infos.append(properties[\"length\"])\n",
    "        infos.append(properties[\"width\"])\n",
    "        infos.append(properties[\"kept_percentage\"])\n",
    "        infos.append(speed)\n",
    "        infos.append(image_path)\n",
    "        l_res.append(infos)\n",
    "    return l_res\n",
    "\n",
    "\n",
    "def boat_into_to_csv(csv_name, list_label_path, list_sample_path):\n",
    "    \"\"\"\n",
    "    Create a csv containing all information for each boat.\n",
    "    The record_id duplicate are dropped by keeping the max kept_percentage\n",
    "    :param csv_name: String, Name of the csv saved\n",
    "    :param list_label_path: List, all label path get from create_list_label_sample\n",
    "    :param list_sample_path: List, all sample path get from create_list_label_sample\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    l_info = []\n",
    "    col_names = [\"record_id\", \"xmin\", \"xmax\", \"ymin\", \"ymax\", \"angle\", \"length\", \"width\", \"kept_percentage\", \"tag\", \"image_path\"]\n",
    "    for label_path, image_path in tqdm(zip(list_label_path, list_sample_path), total=len(list_label_path)):\n",
    "        l_info += boat_info_from_json(label_path, image_path)\n",
    "    # Transform list to Pandas dataframe\n",
    "    df_info = pd.DataFrame(l_info, columns=col_names)\n",
    "    # Removing duplicate record_id by keeping only the best 'kept_percentage'\n",
    "    df_info = df_info.groupby('record_id', group_keys=False).apply(lambda x: x.loc[x.kept_percentage.idxmax()])\n",
    "    df_info.to_csv(csv_name, sep=\",\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image_and_csv_with_different_bounding_box(csv_name_clean, csv_name, data_clean_dir, grid_box):\n",
    "    df_info = pd.read_csv(csv_name)\n",
    "    l_dir_record_clean = []\n",
    "    for index, row in tqdm(df_info.iterrows(), total=len(df_info)):\n",
    "        img = io.imread(row[\"image_path\"])\n",
    "        coord = [row[\"xmin\"], row[\"xmax\"], row[\"ymin\"], row[\"ymax\"]]\n",
    "        record_id = row[\"record_id\"]\n",
    "        list_box = create_list_box(img, coord, grid_box)\n",
    "        l_dir_image_clean = save_list_box(list_box, grid_box, data_clean_dir, record_id)\n",
    "        l_dir_record_clean += l_dir_image_clean\n",
    "    df_dir_record_clean = pd.DataFrame(l_dir_record_clean, columns=[\"record_id\", \"image_clean_path\"])\n",
    "    df_dir_record_clean = df_dir_record_clean.set_index(\"record_id\").join(df_info.set_index(\"record_id\")).reset_index()\n",
    "    df_dir_record_clean.to_csv(csv_name_clean, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 199/200 [00:04<00:00, 36.72it/s]\n"
     ]
    }
   ],
   "source": [
    "csv_name = \"../toto.csv\"\n",
    "csv_name_clean = \"../toto_clean.csv\"\n",
    "\n",
    "grid_box = [100, 150, 200]\n",
    "data_clean_dir = \"data_clean\"\n",
    "generate_image_and_csv_with_different_bounding_box(csv_name_clean, csv_name, data_clean_dir, grid_box)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1[\"record_id\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.imread(\"/classification_speed_boat/data/train/samples/84a411c4-4d26-4a49-b97c-2e9fc0f29188/a6b56f6292926b7d210d35d0dc3596505899245c/5939e669996d3c65065ece70ee964512.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.set_index(\"record_id\").join(df2.set_index(\"record_id\")).reset_index().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_info.iterrows():\n",
    "    print(row[\"xmax\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path\n",
    "root_dir_train = \"/home/maxence/Documents/hackathon/train\"\n",
    "root_dir_valid = \"/home/maxence/Documents/hackathon/valid\"\n",
    "# Arg for transformation\n",
    "size = 258\n",
    "transform = transforms.Compose([transforms.Resize((size, size)),\n",
    "                                transforms.ToTensor()])\n",
    "# Create dataframe\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_dataset = SatelliteImageDataset(root_dir_train, transform, device)\n",
    "valid_dataset = SatelliteImageDataset(root_dir_train, transform, device)\n",
    "# create loader\n",
    "batch_size = 64\n",
    "num_worker = 0\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                          num_workers=num_worker, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size,\n",
    "                          num_workers=num_worker, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))\n",
    "print(batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_tensor_image(batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
