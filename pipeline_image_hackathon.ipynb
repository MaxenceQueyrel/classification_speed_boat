{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import skimage\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "from pprint import pprint\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SatelliteImageDataset(Dataset):\n",
    "    \"\"\"Load a satellite dataset\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, transform=None, device=torch.device(\"cpu\")):\n",
    "        \"\"\"\n",
    "        Create a satellite image dataset\n",
    "        :param root_dir: String, The path where are stored the images\n",
    "        :param transform: torchvion transform function, Optional transform to be applied\n",
    "                on an image.\n",
    "        :device: Pytorch device: cpu or gpu to move the data into the good device\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.L_image_name = os.listdir(root_dir)\n",
    "        self.transform = transform\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.L_image_name)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        image = pil_loader(os.path.join(self.root_dir,\n",
    "                             self.L_image_name[idx]))\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image.to(self.device)\n",
    "\n",
    "def pil_loader(path):\n",
    "    \"\"\"\n",
    "    Load an image into PIL format and convert it into RGB    \n",
    "    :param path: String, Complete path of the image file\n",
    "    :return: PIL image\n",
    "    \"\"\"\n",
    "    image = Image.open(path)\n",
    "    return image.convert(\"RGB\")\n",
    "    \n",
    "def show_tensor_image(tensor):\n",
    "    \"\"\"\n",
    "    Take a tensor and show the corresponding image\n",
    "    :param tensor: Pytorch Tensor, [channels, height, width]\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    tensor = tensor.transpose(0, 1)\n",
    "    tensor = tensor.transpose(1, 2)\n",
    "    io.imshow(tensor.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "def create_list_label_sample(data_dir, dataset_name):\n",
    "    def list_sorted(name):\n",
    "        list_ = []\n",
    "        for dir_, _, filenames in os.walk(os.path.join(data_dir,dataset_name, name)):\n",
    "            for f in filenames:\n",
    "                if f[0] != \".\":\n",
    "                    list_.append(os.path.abspath(os.path.join(dir_, f)))\n",
    "        list_.sort(key=lambda f: f.split('/')[-1])\n",
    "        return list_\n",
    "    list_sample_path, list_label_path = list_sorted(\"samples\"), list_sorted(\"labels\")\n",
    "    set_sample_id = set(list(map(lambda x: x.split('/')[-1].replace(\".jpg\",\"\"), list_sample_path)))\n",
    "    set_label_id = set(list(map(lambda x: x.split('/')[-1].replace(\".json\",\"\"), list_label_path)))\n",
    "    id_diff = set_sample_id.difference(set_label_id)\n",
    "    id_diff.update(set_label_id.difference(set_sample_id))\n",
    "    list_sample = list(filter(lambda x: x.split('/')[-1].replace(\".jpg\",\"\") not in id_diff, list_sample_path))\n",
    "    list_label_path= list(filter(lambda x: x.split('/')[-1].replace(\".json\",\"\") not in id_diff, list_label_path))\n",
    "    return list_sample_path, list_label_path\n",
    "    \n",
    "# Path\n",
    "data_dir = \"/classification_speed_boat/data/\"\n",
    "dataset_name = \"train\"\n",
    "\n",
    "list_sample_path, list_label_path = create_list_label_sample(data_dir, dataset_name)\n",
    "print(np.array([i.split('/')[-1][:-5] != j.split('/')[-1][:-6] for i,j in (zip(list_sample_path, list_label_path))]).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "data_dir2 = \"/classification_speed_boat/data/\"\n",
    "dataset_name2 = \"test_students\"\n",
    "\n",
    "list_sample_path2, list_label_path2 = create_list_label_sample(data_dir2, dataset_name2)\n",
    "print(np.array([i.split('/')[-1][:-5] != j.split('/')[-1][:-6] for i,j in (zip(list_sample_path2, list_label_path2))]).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = list_sample_path[0]\n",
    "label = list_label_path[80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/classification_speed_boat/data/train/samples/431c7e24-dab7-41de-b568-d8ad25b39704/ac152bf238910f22d049f9ba315686fc0ad8688e/00007ef36dd75f697905cda4d3c90dc7.jpg'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor label in list_label2:\\n    with open(label, \\'rb\\') as f:\\n        boat_info = json.load(f)\\n        for elem in boat_info[\"features\"]:\\n            if \"record_id\" in elem[\"properties\"]:\\n                pprint(elem[\"properties\"]) \\n                break\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for label in list_label2:\n",
    "    with open(label, 'rb') as f:\n",
    "        boat_info = json.load(f)\n",
    "        for elem in boat_info[\"features\"]:\n",
    "            if \"record_id\" in elem[\"properties\"]:\n",
    "                pprint(elem[\"properties\"]) \n",
    "                break\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'features': [{'geometry': {'coordinates': [[[768.0, 600.4],\n",
      "                                             [751.8, 605.8],\n",
      "                                             [754.3, 613.6],\n",
      "                                             [768.0, 609.1],\n",
      "                                             [768.0, 600.4]]],\n",
      "                            'type': 'Polygon'},\n",
      "               'properties': {'angle': 71.7,\n",
      "                              'comment': None,\n",
      "                              'confidence': None,\n",
      "                              'created_at': '2019-09-26T12:22:56.101046',\n",
      "                              'dataset_id': '21928740-73ad-44db-8517-6f1ea076876c',\n",
      "                              'id': 'record.5ea3398c-e058-11e9-a9bf-4e46ad189ba4',\n",
      "                              'image_2_id': None,\n",
      "                              'image_id': '37c89d0527e0edbe0b0d589e94715780731af818',\n",
      "                              'job_id': None,\n",
      "                              'jobtask_id': None,\n",
      "                              'kept_percentage': 0.36553128308620325,\n",
      "                              'length': 51.7,\n",
      "                              'orientation': None,\n",
      "                              'record_id': '5ea3398c-e058-11e9-a9bf-4e46ad189ba4',\n",
      "                              'state': 'ADDED',\n",
      "                              'surface': 508.7,\n",
      "                              'tags': ['ship', 'merchant_vessel', 'slow'],\n",
      "                              'width': 9.8,\n",
      "                              'zone_id': '5586a344-db54-46e7-897e-296d070a428d'},\n",
      "               'type': 'Feature'},\n",
      "              {'geometry': {'coordinates': [[[118.4, 530.3],\n",
      "                                             [121.3, 538.1],\n",
      "                                             [126.4, 536.1],\n",
      "                                             [123.5, 528.4],\n",
      "                                             [118.4, 530.3]]],\n",
      "                            'type': 'Polygon'},\n",
      "               'properties': {'angle': 339.5,\n",
      "                              'comment': None,\n",
      "                              'confidence': None,\n",
      "                              'created_at': '2019-09-26T12:22:56.101215',\n",
      "                              'dataset_id': '21928740-73ad-44db-8517-6f1ea076876c',\n",
      "                              'id': 'record.5ea34044-e058-11e9-a9bf-4e46ad189ba4',\n",
      "                              'image_2_id': None,\n",
      "                              'image_id': '37c89d0527e0edbe0b0d589e94715780731af818',\n",
      "                              'job_id': None,\n",
      "                              'jobtask_id': None,\n",
      "                              'kept_percentage': 1.0,\n",
      "                              'length': 10.0,\n",
      "                              'orientation': None,\n",
      "                              'record_id': '5ea34044-e058-11e9-a9bf-4e46ad189ba4',\n",
      "                              'state': 'ADDED',\n",
      "                              'surface': 65.9,\n",
      "                              'tags': ['fishing_vessel', 'ship', 'slow'],\n",
      "                              'width': 6.6,\n",
      "                              'zone_id': '5586a344-db54-46e7-897e-296d070a428d'},\n",
      "               'type': 'Feature'},\n",
      "              {'geometry': {'coordinates': [[[493.4, 184.7],\n",
      "                                             [491.7, 186.0],\n",
      "                                             [495.2, 190.8],\n",
      "                                             [497.0, 189.5],\n",
      "                                             [493.4, 184.7]]],\n",
      "                            'type': 'Polygon'},\n",
      "               'properties': {'angle': 323.6,\n",
      "                              'comment': None,\n",
      "                              'confidence': None,\n",
      "                              'created_at': '2019-09-26T12:22:56.101748',\n",
      "                              'dataset_id': '21928740-73ad-44db-8517-6f1ea076876c',\n",
      "                              'id': 'record.5ea353ea-e058-11e9-a9bf-4e46ad189ba4',\n",
      "                              'image_2_id': None,\n",
      "                              'image_id': '37c89d0527e0edbe0b0d589e94715780731af818',\n",
      "                              'job_id': None,\n",
      "                              'jobtask_id': None,\n",
      "                              'kept_percentage': 1.0,\n",
      "                              'length': 7.2,\n",
      "                              'orientation': None,\n",
      "                              'record_id': '5ea353ea-e058-11e9-a9bf-4e46ad189ba4',\n",
      "                              'state': 'ADDED',\n",
      "                              'surface': 18.8,\n",
      "                              'tags': ['fishing_vessel', 'ship', 'slow'],\n",
      "                              'width': 2.6,\n",
      "                              'zone_id': '5586a344-db54-46e7-897e-296d070a428d'},\n",
      "               'type': 'Feature'},\n",
      "              {'geometry': {'coordinates': [[[21.3, 768.0],\n",
      "                                             [768.0, 768.0],\n",
      "                                             [768.0, 51.4],\n",
      "                                             [21.3, 51.4],\n",
      "                                             [21.3, 768.0]]],\n",
      "                            'type': 'Polygon'},\n",
      "               'properties': {'kept_percentage': 0.9072230445368449,\n",
      "                              'mask': True},\n",
      "               'type': 'Feature'}],\n",
      " 'type': 'FeatureCollection'}\n"
     ]
    }
   ],
   "source": [
    "with open(label, 'rb') as f:\n",
    "    boat_info = json.load(f)\n",
    "pprint(boat_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[768.0, 600.4],\n",
       " [751.8, 605.8],\n",
       " [754.3, 613.6],\n",
       " [768.0, 609.1],\n",
       " [768.0, 600.4]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = boat_info[\"features\"][0][\"geometry\"][\"coordinates\"][0]\n",
    "boat_info[\"features\"][0][\"geometry\"][\"coordinates\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "751.8"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.array(t)\n",
    "np.min(t[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polygone_to_min_max_coordinates(polygone):\n",
    "    # Remove the last point that correspond to the first one\n",
    "    polygone = np.array(polygone[:-1])\n",
    "    # Get min and max coordinates transformed to int\n",
    "    xmin = int(np.min(polygone[:,0]))\n",
    "    xmax = int(np.max(polygone[:,0])) + 1\n",
    "    ymin = int(np.min(polygone[:,1]))\n",
    "    ymax = int(np.max(polygone[:,1])) + 1\n",
    "    return xmin, xmax, ymin, ymax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boat_info_from_json(label_path, image_path):\n",
    "    # read the json file containing the boat info\n",
    "    with open(label_path, 'rb') as f:\n",
    "        boat_info = json.load(f)\n",
    "    # l_res contains the final info to keep\n",
    "    l_res = []\n",
    "    for feature in boat_info[\"features\"]:\n",
    "        properties = feature[\"properties\"]\n",
    "        infos = []\n",
    "        # Finding the speed tag if not exists continue\n",
    "        if \"tags\" not in properties:\n",
    "            continue\n",
    "        speed = None\n",
    "        for speed_tag in [\"idle\", \"fast\", \"slow\"]:\n",
    "            if speed_tag in properties[\"tags\"]:\n",
    "                speed = speed_tag\n",
    "        # If there is not a record_id or not speed tag then continue\n",
    "        if \"record_id\" not in properties or speed is None:\n",
    "            continue\n",
    "        xmin, xmax, ymin, ymax = polygone_to_min_max_coordinates(feature[\"geometry\"][\"coordinates\"][0])\n",
    "        infos.append(properties[\"record_id\"])\n",
    "        # Appending all infos\n",
    "        infos.append(xmin)\n",
    "        infos.append(xmax)\n",
    "        infos.append(ymin)\n",
    "        infos.append(ymax)\n",
    "        infos.append(properties[\"angle\"])\n",
    "        infos.append(properties[\"length\"])\n",
    "        infos.append(properties[\"width\"])\n",
    "        infos.append(properties[\"kept_percentage\"])\n",
    "        infos.append(speed)\n",
    "        infos.append(image_path)\n",
    "        l_res.append(infos)\n",
    "    return l_res\n",
    "\n",
    "def boat_into_to_csv(file_name_res, list_label_path, list_sample_path):\n",
    "    l_info = []\n",
    "    col_names = [\"record_id\", \"xmin\", \"xmax\", \"ymin\", \"ymax\", \"angle\", \"length\", \"width\", \"kept_percentage\", \"tag\", \"image_path\"]\n",
    "    for label_path, image_path in zip(list_label_path, list_sample_path):\n",
    "        l_info += boat_info_from_json(label_path, image_path)\n",
    "    # Transform list to Pandas dataframe\n",
    "    df_info = pd.DataFrame(l_info, columns=col_names)\n",
    "    # Removing duplicate record_id by keeping only the best 'kept_percentage'\n",
    "    df_info = df_info.groupby('record_id', group_keys=False).apply(lambda x: x.loc[x.kept_percentage.idxmax()])\n",
    "    df_info.to_csv(file_name_res, sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "boat_into_to_csv(\"toto.csv\", list_label_path, list_sample_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info = pd.read_csv(\"toto.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(333,)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_info[\"zone_id\"].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path\n",
    "root_dir_train = \"/home/maxence/Documents/hackathon/train\"\n",
    "root_dir_valid = \"/home/maxence/Documents/hackathon/valid\"\n",
    "# Arg for transformation\n",
    "size = 258\n",
    "transform = transforms.Compose([transforms.Resize((size, size)),\n",
    "                                transforms.ToTensor()])\n",
    "# Create dataframe\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_dataset = SatelliteImageDataset(root_dir_train, transform, device)\n",
    "valid_dataset = SatelliteImageDataset(root_dir_train, transform, device)\n",
    "# create loader\n",
    "batch_size = 64\n",
    "num_worker = 0\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                          num_workers=num_worker, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size,\n",
    "                          num_workers=num_worker, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))\n",
    "print(batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_tensor_image(batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
